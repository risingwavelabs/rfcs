---
feature: Stream Executor with EMIT ON WINDOW CLOSE Semantics
authors:
  - "st1page"
start_date: "2023/02/14"
---

# Stream Executor with EMIT ON WINDOW CLOSE Semantics

## Summary

Introduce a new component Sort Buffer used in the streaming executor and give a general method to implement EMIT ON WINDOW CLOSE stream executor. Sort Buffer can support materialize and persistent the changes stream and drain the "stable" records with the input watermark. Because the input watermarks are always monotonically increasing, the output records are ordered by the watermark column and append-only.

***Note: In this RFC, we will focus on the EMIT ON WINDOW CLOSE query***

## Background and Definitions

Let's look back on the current designs and RFCs.

The [RFC: The Semantics of EMIT ON WINDOW CLOSE](https://github.com/risingwavelabs/rfcs/pull/30) has given a strict definition of the semantics of **EMIT ON WINDOW CLOSE**. In short, the streaming job with the "EMIT ON WINDOW CLOSE" modifier emits the result when the window is closed and the result is complete, and no sooner, no later. 

According to the same RFC(EMIT ON WINDOW CLOSE), The **User-defined Watermark** on the source make the user a way to declare which records from the source are outdated and can be discarded. Watermark gives a bound of the data as the data inputs, which provides the guarantee that some results are complete and triggers the emitting of the EMIT ON WINDOW CLOSE query.

And [RFC: The WatermarkFilter and StreamSort operator](https://github.com/risingwavelabs/rfcs/pull/2) introduces the WatermarkFilter stream operator. With the "user-defined watermark" and continuous ingested data, WatermarkFilter can generate consistent **Internal Watermark Stream Message** (hereinafter referred to as **"Watermark"** or **"Watermark message"**). A Watermark message with column index and value means there will be no data that have a larger watermark column value than the value in the watermark.

Also, the RFC proposes the **Watermark Derivation** of the stream operator. This design makes sure that all possible trigger messages generated by **User-defined Watermark** can be expressed as the **Watermark message**. The only thing that can transfer between
the stream operator is the Watermark message so the stream operator does not need to be aware of the "time window" or other concepts. The executor just needs to handle the input watermark no matter whether the watermark column is a "window_close" or a temporal filter's output column.

And then we can introduce **EMIT ON WINDOW CLOSE Flag** on any stream operator now. The stream operator with the flag works can make sure some result is complete with the input watermark and then emit them. If most downstream stream operator has EMIT ON WINDOW CLOSE Flag, the streaming query can satisfy the EMIT ON WINDOW CLOSE semantics.

In this RFC, we will focus on how to implement a stream executor with EMIT ON WINDOW CLOSE flag and reuse the logic of the normal stream executor.

## Sort Buffer Design

Compared with the normal stream executor, the EMIT ON WINDOW CLOSE executor needs to buffer the data until the result is complete. A general component `SortBuffer` is introduced here for executors.
SortBuffer consists of two parts, SortBufferCache and SortBufferTable.

- SortBufferTable
  - A stateTable to persist the buffered data.
  - The primary key's first column is a watermark column. We call it as **sort key**
- SortBufferCache
  - A row cache on the SortBufferTable
  - can accept watermark to know some rows have been complete
  - can drain the complete row in the memory ordered by the sort key.

And the SortBufferTable is just a normal StateTable, we will only need to implement the SortBufferCache.

```rust
impl SortBufferCache{
  /// consume the next row ordered by the first column which is complete.
  /// return None if there is no remaining complete row.
  /// fill cache from the stateTable when cache miss.
  /// will consume the row in memory.
  fn next(&mut self, table: &StateTable) -> Option<Row>;

  /// get the minimum sort key in rows which is complete.
  /// return None if there is no remaining complete row.
  /// fill cache from the stateTable when cache miss.
  /// will not consume the row in memory.
  fn peek_sort_key(&self, table: &StateTable) -> Option<ScalarImpl>;

  /// use the first column's watermark to refresh the SortBuffer
  /// can trigger more rows complete which can be returned by `self.next`
  fn accept_watermark(&mut self, watermark: Watermark);
  
  /// apply changes operations
  fn insert(&mut self, row: Row);
  fn delete(&mut self, row: Row);
  fn apply_chunk(&mut self, c: Chunk);

  /// recovery from the stateTable, just gets the row belonging to stateTable's vnode.
  fn recovery(&mut self, table: &StateTable);
}

```

The component does not take over so many things. There are still lots of things that should be done by the executor, such as

- all the operations should be applied on the table and cache, and the executor should write in duplicate.
- after getting the complete data, the executor must delete the useless data by itself (delete one by one/range delete with the last key). Notice that it is different with state clean and the data must be deleted consistently.

And then we will see why and how it works in different situations.

## Executors

### Sort

SortExecutor just has a executor which wraps a SortBuffer which can transform any stream into a append only stream ordered by a watermark column.

- when stream chunk arrive
  - write the chunk into stateTable
  - write the chunk into SortBufferCache
- when watermark arrive
  - pass watermark into SortBufferCache
- when barrier arrive
  - drain complete rows from SortBufferCache, for each rows
    - emit the row downstream
    - delete the row in stateTable

### SortAgg (with batch only agg calls)

Under "EMIT ON WINDOW CLOSE" semantics, if there is watermark in group key, we can use SortExecutor for the input stream, and then we get a sorted stream which can be processed by "BatchSortAgg". Then, we can support all the aggregators which can run in batch mode.

The SortAgg supports more kinds of aggregators under "EMIT ON WINDOW CLOSE", but should materialized all the input data, which could be worse than the normal streamGroupAgg. So we have another EMIT ON WINDOW CLOSE GroupAgg implementation as described below. I think the SortAgg is just to solve some aggregation functions which does not have a streaming version(hard to implement or with high cost)

### GroupAgg

If there is watermark in group key, the EMIT ON WINDOW CLOSE GroupAgg calculate the aggregation with the same logic with streamGroupAgg, But it only emit the complete part of the agg result. A simple idea is add a sortExecutor after a normal streamGroupAgg and we can find that the streamGroupAgg's result table and sortExecutor's stateTable exactly have the same schema and meaning.

So the EMIT ON WINDOW CLOSE streamGroupAgg need only add a SortBufferCache on the agg's result table.

- when stream chunk arrive
  - do the same with normal streamGroupAgg
- when watermark arrive
  - pass watermark into SortBufferCache
- when barrier arrive
  - do the same with normal streamGroupAgg but not emit to down stream, just get the changes
    - write the changes into SortBufferCache
    - write the changes into result table
    - (the LRU cache should has been changed by the agg's logic)
  - drain complete rows from SortBufferCache, for each rows
    - emit the row downstream
    - delete the row in result table
  - emit watermark with the last emitted row's watermark

### OverAgg

[RFC: Over Window on watermark](https://github.com/risingwavelabs/rfcs/pull/8)
We still need more detailed design here, but it is clear that the row's complete and row's emit can not always happens at the same time.

### EqJoin

It likes window join in Flink.
When there are watermarks in the first join key of the both two sides. We can use two SortBuffers(table and cache) to implement a sortMergeJoin. SortBuffer’s `peek` method is used here.

### IntervalJoin


We have discussed about the band join in [RFC: Band Join](https://github.com/risingwavelabs/rfcs/pull/32). And we will support the EMIT ON CLOSE interval join with these formal definition which is same with FlinkSQL.	
there should be at least one equal join key to shuffle and parallel process.

The interval condition should be on the two column. Considering they are `l_t` and `r_t`. The condition should be always able to transform to the following forms. l_t between interval(r_t, r_t + constant)

There are two tables for one side and four tables in total. Assuming that the `l_t`, `r_t` as the watermark columns, `l_pk`, `r_pk` are the stream keys and `l_k`, `r_k` as the equal join key, the tables primary keys are:

- left state table: [l_k, l_t, l_pk]
- left sort table: [l_t, l_k, l_pk]
- right state table: [r_k, r_t, r_pk]
- right sort table: [r_t, t_k, r_pk]

The sort table is optimized to get the complete rows and the state table is optimized to match by equal key. The executor’s computing logic is that

1. get the lowest complete row **R** from one side’s sort buffer
2. Using the peek value from the other side’s sort buffer, check if the other side rows is complete match the **R** with the interval condition. If yes, consume the R from the sort buffer and go on
3. Get the rows in the other side’s state table with the join key and get all the rows which satisfy the equal condition and interval condition to do join calculation and emit the result.
4. Delete the R in the state table

And to accelerate the processing, we need to add the SortBuffer cache on the sort table and add a LRU cache on the state table. And because of the interval join's property, the read pattern is to find in a lowest time's interval with a group join key. So the cache strategy is the same as the cache of the max/min aggregator.